{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Pipeline Script for Trainval and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from os import getcwd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler    # scaling the data\n",
    "from sklearn.feature_selection import SelectFpr, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trainval data\n",
    "trainval_path = getcwd() + r'\\MLN Assessment Data-20240207\\training_validation.csv' # Define file directory for training and validation data\n",
    "trainval = pd.read_csv(trainval_path) # Import csv\n",
    "\n",
    "# Import test data\n",
    "test_path = getcwd() + r'\\MLN Assessment Data-20240207\\test.csv' # Define file directory for test data\n",
    "test = pd.read_csv(test_path) # Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 296)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check trainval shape is as expected\n",
    "trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split trainval into 2 training sets (one for stage one and one for stage two)\n",
    "\n",
    "# Create category to stratify split\n",
    "num_bins = 6        # Number of bins\n",
    "\n",
    "# Create bin categories for age data\n",
    "age_bins = pd.cut(trainval['Age'], bins=num_bins).tolist()\n",
    "\n",
    "# Create a list by combining the bins and diagnosis\n",
    "combined_age_diagnosis = [f\"{age_bin}_{diagnosis}\" for age_bin, diagnosis in zip(age_bins, trainval['Diagnosis'])]\n",
    "\n",
    "# Stratify split data based on age and diagnosis\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15, random_state = 5)\n",
    "\n",
    "for i, (stageone_ind, stagetwo_ind) in enumerate(sss.split(trainval, combined_age_diagnosis)): \n",
    "    stage1_trainval = trainval.iloc[stageone_ind,:]\n",
    "    stage2_trainval = trainval.iloc[stagetwo_ind,:]\n",
    "\n",
    "X1_trainval = stage1_trainval.iloc[:,4:]             # MRI features\n",
    "y1_trainval = stage1_trainval['Diagnosis']      # Diagnosis\n",
    "\n",
    "X2_trainval = stage1_trainval.iloc[:,4:]             # MRI features\n",
    "y2_trainval = stage1_trainval['Age']            # Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that applies stage one and creates a new dataset to be used for stage two\n",
    "def prepare_stage2_data(X_data, pipe):\n",
    "\n",
    "    \"\"\"\n",
    "    Perform stage one modelling by using trained pipeline to predict y values on X_data. \n",
    "    These predictions for diagnosis probabilities are then concatenated to X_data.\n",
    "    This allows the X_data to be used ready for stage two.\n",
    "\n",
    "    Parameters:\n",
    "    - X_data: Training data features for stage two.\n",
    "    - pipe: Trained stage one pipeline\n",
    "\n",
    "    Returns:\n",
    "    - stage2_Xtrain: Dataset for stage two modelling.\n",
    "    \"\"\"\n",
    "\n",
    "    y1_pred = pipe.predict_proba(X_data)\n",
    "\n",
    "    # Convert predicted probabilities and test data to dataframes\n",
    "    pred_probs_df = pd.DataFrame(y1_pred, columns=pipe.classes_)\n",
    "    stage1_data_df = pd.DataFrame(X_data)\n",
    "\n",
    "    # Reset the index of the dataframes\n",
    "    pred_probs_df.reset_index(drop=True, inplace=True)\n",
    "    stage1_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Concatenate the test data and predicted probabilities\n",
    "    stage2_data = pd.concat([stage1_data_df, pred_probs_df], axis=1)\n",
    "\n",
    "    return stage2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stage one pipeline\n",
    "stage1_pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                            ('selector', SelectFpr(alpha=0.025)),\n",
    "                            ('classifier', RandomForestClassifier(max_depth=14, min_samples_split=4,\n",
    "                                        n_estimators=150, random_state=3))])\n",
    "stage1_pipeline.fit(X1_trainval, y1_trainval)\n",
    "\n",
    "# Create X2 data ready for stage two\n",
    "X2_trainval = prepare_stage2_data(X1_trainval, stage1_pipeline)\n",
    "X2_test = prepare_stage2_data(test, stage1_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data by adding diagnosis predictions\n",
    "# Define stage 2 pipeline\n",
    "stage2_pipeline = Pipeline([('scaler', StandardScaler()), \n",
    "                            ('selector', SelectFpr(alpha=0.05)),\n",
    "                            ('regressor', RandomForestRegressor(max_depth=10, min_samples_split=10,\n",
    "                                                                n_estimators=150, random_state=0))])\n",
    "stage2_pipeline.fit(X2_trainval, y2_trainval)\n",
    "\n",
    "y2_pred = stage2_pipeline.predict(X2_test)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array to pandas Series\n",
    "y2_pred_series = pd.Series(y2_pred)\n",
    "\n",
    "# Export to CSV\n",
    "y2_pred_series.to_csv('predictions.csv', index=False, header=['Age'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
